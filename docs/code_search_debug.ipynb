{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code search debug setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example setup for debugging aspects of the code_search example. This should make it easier to debug and write tests for various aspects of the model as well as provide a simple interface for exploring its performance during development.\n",
    "\n",
    "Fairly similar to [hello_t2t.ipynb](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb).\n",
    "\n",
    "Currently appears to require tf 1.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from six import StringIO\n",
    "import tempfile\n",
    "\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.models import transformer\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import t2t_model\n",
    "\n",
    "from tensor2tensor.data_generators import generator_utils\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tk\n",
    "\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@registry.register_problem\n",
    "class GithubFunctionDocstring(text_problems.Text2TextProblem):\n",
    "  \"\"\"Function and Docstring similarity Problem.\n",
    "  This problem contains the data consisting of function\n",
    "  and docstring pairs as CSV files. The files are structured\n",
    "  such that they contain two columns without headers containing\n",
    "  the docstring tokens and function tokens. The delimiter is\n",
    "  \",\".\n",
    "  \"\"\"\n",
    "\n",
    "  DATA_PATH_PREFIX = \"gs://kubeflow-examples/t2t-code-search/raw_data\"\n",
    "\n",
    "  @property\n",
    "  def pair_files_list(self):\n",
    "    \"\"\"Return URL and file names.\n",
    "    This format is a convention across the Tensor2Tensor (T2T)\n",
    "    codebase. It should be noted that the file names are currently\n",
    "    hardcoded. This is to preserve the semantics of a T2T problem.\n",
    "    In case a change of these values is desired, one must subclass\n",
    "    and override this property.\n",
    "    # TODO(sanyamkapoor): Manually separate train/eval data set.\n",
    "    Returns:\n",
    "      A list of the format,\n",
    "        [\n",
    "          [\n",
    "            \"STRING\",\n",
    "            (\"STRING\", \"STRING\", ...)\n",
    "          ],\n",
    "          ...\n",
    "        ]\n",
    "      Each element is a list of size 2 where the first represents\n",
    "      the source URL and the next is an n-tuple of file names.\n",
    "      In this case, the tuple is of size 1 because the URL points\n",
    "      to a file itself.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [\n",
    "            \"{}/func-doc-pairs-000{:02}-of-00100.csv\".format(\n",
    "                self.DATA_PATH_PREFIX, i),\n",
    "            (\"func-doc-pairs-000{:02}-of-00100.csv\".format(i),)\n",
    "        ]\n",
    "        for i in range(1)\n",
    "    ]\n",
    "\n",
    "  @property\n",
    "  def is_generate_per_split(self):\n",
    "    return False\n",
    "\n",
    "  @property\n",
    "  def approx_vocab_size(self):\n",
    "    return 2**13\n",
    "\n",
    "  @property\n",
    "  def max_samples_for_vocab(self):\n",
    "    # FIXME(sanyamkapoor): This exists to handle memory explosion.\n",
    "    return int(2e5)\n",
    "\n",
    "  def get_csv_files(self, _data_dir, tmp_dir, _dataset_split):\n",
    "    return [\n",
    "        generator_utils.maybe_download(tmp_dir, file_list[0], uri)\n",
    "        for uri, file_list in self.pair_files_list\n",
    "    ]\n",
    "\n",
    "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
    "    \"\"\"A generator to return data samples.Returns the data generator to return.\n",
    "    Args:\n",
    "      data_dir: A string representing the data directory.\n",
    "      tmp_dir: A string representing the temporary directory and is\n",
    "              used to download files if not already available.\n",
    "      dataset_split: Train, Test or Eval.\n",
    "    Yields:\n",
    "      Each element yielded is of a Python dict of the form\n",
    "        {\"inputs\": \"STRING\", \"targets\": \"STRING\", \"embed_code\": [0]}\n",
    "    \"\"\"\n",
    "    csv_files = self.get_csv_files(data_dir, tmp_dir, dataset_split)\n",
    "\n",
    "    for pairs_file in csv_files:\n",
    "      tf.logging.debug(\"Reading {}\".format(pairs_file))\n",
    "      with tf.gfile.Open(pairs_file) as csv_file:\n",
    "        for line in csv_file:\n",
    "          reader = csv.reader(StringIO(line))\n",
    "          for docstring_tokens, function_tokens in reader:\n",
    "            yield {\n",
    "                \"inputs\": docstring_tokens,\n",
    "                \"targets\": function_tokens,\n",
    "                \"embed_code\": [0]\n",
    "            }\n",
    "\n",
    "  def example_reading_spec(self):\n",
    "    data_fields, data_items_to_decoders = super(GithubFunctionDocstring,\n",
    "                                                self).example_reading_spec()\n",
    "    data_fields[\"embed_code\"] = tf.FixedLenFeature([1], dtype=tf.int64)\n",
    "\n",
    "    data_items_to_decoders = {\n",
    "      \"inputs\": tf.contrib.slim.tfexample_decoder.Tensor(tensor_key=\"inputs\"),\n",
    "      \"targets\": tf.contrib.slim.tfexample_decoder.Tensor(tensor_key=\"targets\"),\n",
    "      \"embed_code\": tf.contrib.slim.tfexample_decoder.Tensor(tensor_key=\"embed_code\")\n",
    "    }\n",
    "    return data_fields, data_items_to_decoders\n",
    "\n",
    "  def eval_metrics(self):  # pylint: disable=no-self-use\n",
    "    return [\n",
    "        metrics.Metrics.ACC\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your paths here!\n",
    "\n",
    "tmp_dir = \"/mnt/nfs-east1-d/cs/tmp\"\n",
    "tf.gfile.MakeDirs(tmp_dir)\n",
    "\n",
    "data_dir = \"/mnt/nfs-east1-d/cs/data\"\n",
    "tf.gfile.MakeDirs(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found vocab file: /mnt/nfs-east1-d/cs/data/vocab.github_function_docstring.8192.subwords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:52,665] Found vocab file: /mnt/nfs-east1-d/cs/data/vocab.github_function_docstring.8192.subwords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:52,745] Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:52,759] Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "problem_object = GithubFunctionDocstring()\n",
    "\n",
    "problem_object.generate_data(data_dir, tmp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from /mnt/nfs-east1-d/cs/data/github_function_docstring-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:52,853] Reading data files from /mnt/nfs-east1-d/cs/data/github_function_docstring-train*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:52,959] partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embed_code': <tf.Tensor: id=52, shape=(1,), dtype=int64, numpy=array([0])>,\n",
      " 'inputs': <tf.Tensor: id=53, shape=(11,), dtype=int64, numpy=array([ 300,   14, 7463,   44, 1686, 1717, 5561,    4,  115,   18,    1])>,\n",
      " 'targets': <tf.Tensor: id=54, shape=(17,), dtype=int64, numpy=\n",
      "array([   7,  300,    2, 7463,   48,    3,   60,  121,    9,    3, 7463,\n",
      "         48,    2,  222,   60,  121,    1])>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example = tfe.Iterator(problem_object.dataset(Modes.TRAIN, data_dir)).next()\n",
    "\n",
    "pprint.pprint(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_name = \"vocab.github_function_docstring.8192.subwords\"\n",
    "\n",
    "# Get the encoders from the problem\n",
    "encoders = problem_object.feature_encoders(data_dir)\n",
    "\n",
    "# Setup helper functions for encoding and decoding\n",
    "def encode(input_str, output_str=None):\n",
    "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
    "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
    "  return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "  \"\"\"List of ints to str\"\"\"\n",
    "  integers = list(np.squeeze(integers))\n",
    "  if 1 in integers:\n",
    "    integers = integers[:integers.index(1)]\n",
    "  return encoders[\"inputs\"].decode(np.squeeze(integers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make a monte carlo sampler object .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(decode(example[\"inputs\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def make_monty self args kwargs return self monty_cls args kwargs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(decode(example[\"targets\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FYI: You can break these losses out and work with them interactively in tf.eager mode\n",
    "# the same as you would a regular python function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_loss(sentence_emb, image_emb, margin=0.2):\n",
    "  \"\"\"Experimental rank loss, thanks to kkurach@ for the code.\"\"\"\n",
    "  with tf.name_scope(\"rank_loss\"):\n",
    "    # Normalize first as this is assumed in cosine similarity later.\n",
    "    sentence_emb = tf.nn.l2_normalize(sentence_emb, 1)\n",
    "    image_emb = tf.nn.l2_normalize(image_emb, 1)\n",
    "    # Both sentence_emb and image_emb have size [batch, depth].\n",
    "    scores = tf.matmul(image_emb, tf.transpose(sentence_emb))  # [batch, batch]\n",
    "    diagonal = tf.diag_part(scores)  # [batch]\n",
    "    cost_s = tf.maximum(0.0, margin - diagonal + scores)  # [batch, batch]\n",
    "    cost_im = tf.maximum(\n",
    "        0.0, margin - tf.reshape(diagonal, [-1, 1]) + scores)  # [batch, batch]\n",
    "    # Clear diagonals.\n",
    "    batch_size = tf.shape(sentence_emb)[0]\n",
    "    empty_diagonal_mat = tf.ones_like(cost_s) - tf.eye(batch_size)\n",
    "    cost_s *= empty_diagonal_mat\n",
    "    cost_im *= empty_diagonal_mat\n",
    "\n",
    "    return cost_s + cost_im\n",
    "    \n",
    "    return cost_s, cost_im\n",
    "    \n",
    "    return tf.reduce_mean(cost_s) + tf.reduce_mean(cost_im)\n",
    "\n",
    "def slicenet_similarity_cost(inputs_encoded, targets_encoded):\n",
    "  \"\"\"Loss telling to be more similar to your own targets than to others.\"\"\"\n",
    "  # This is a first very simple version: handle variable-length by padding\n",
    "  # to same length and putting everything into batch. In need of a better way.\n",
    "  x, y = common_layers.pad_to_same_length(inputs_encoded, targets_encoded)\n",
    "  return rank_loss(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kf_loss(string_embedding, code_embedding):\n",
    "\n",
    "  string_embedding_norm = tf.nn.l2_normalize(string_embedding, axis=1)\n",
    "  code_embedding_norm = tf.nn.l2_normalize(code_embedding, axis=1)\n",
    "  tf.logging.debug(\"string_embedding_norm: %s\" % string_embedding_norm)\n",
    "  tf.logging.debug(\"code_embedding_norm: %s\" % code_embedding_norm)\n",
    "\n",
    "  # All-vs-All cosine distance matrix, reshaped as row-major.\n",
    "  cosine_dist = 1.0 - tf.matmul(string_embedding_norm, code_embedding_norm,\n",
    "                                transpose_b=True)\n",
    "  cosine_dist_flat = tf.reshape(cosine_dist, [-1, 1])\n",
    "  tf.logging.debug(\"cosine_dist_flat: %s\" % cosine_dist_flat)\n",
    "\n",
    "  # Positive samples on the diagonal, reshaped as row-major.\n",
    "  label_matrix = tf.eye(tf.shape(cosine_dist)[0], dtype=tf.int32)\n",
    "  label_matrix_flat = tf.reshape(label_matrix, [-1])\n",
    "  tf.logging.debug(\"label_matrix_flat: %s\" % label_matrix_flat)\n",
    "\n",
    "  logits = tf.concat([1.0 - cosine_dist_flat, cosine_dist_flat], axis=1)\n",
    "  tf.logging.debug(\"logits: %s\" % logits)\n",
    "\n",
    "  labels = tf.one_hot(label_matrix_flat, 2)\n",
    "  tf.logging.debug(\"labels: %s\" % labels)\n",
    "\n",
    "  loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels,\n",
    "                                                 logits=logits)\n",
    "  tf.logging.debug(\"loss: %s\" % loss)\n",
    "\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [3. 4. 3.]\n",
      " [5. 6. 3.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4. 3. 3.]\n",
      " [2. 1. 3.]\n",
      " [7. 8. 3.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.convert_to_tensor(\n",
    "    np.array([[1.0, 2.0, 3.0], [3.0, 4.0, 3.0], [5.0, 6.0, 3.0]], dtype=np.float32),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "t2 = tf.convert_to_tensor(\n",
    "    np.array([[4.0, 3.0, 3.0], [2.0, 1.0, 3.0], [7.0, 8.0, 3.0]], dtype=np.float32),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.3132617  0.69314724]\n",
      "  [0.33635572 0.735665  ]\n",
      "  [0.32775706 0.7199305 ]]\n",
      "\n",
      " [[0.33635572 0.735665  ]\n",
      "  [1.3132616  0.6931471 ]\n",
      "  [0.3868397  0.8258845 ]]\n",
      "\n",
      " [[0.32775706 0.7199305 ]\n",
      "  [0.3868397  0.8258845 ]\n",
      "  [1.3132617  0.69314724]]], shape=(3, 3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1.2205269  0.6306621 ]\n",
      "  [0.33297884 0.7294991 ]\n",
      "  [0.37914097 0.8123544 ]]\n",
      "\n",
      " [[0.32125714 0.70796114]\n",
      "  [1.2205269  0.6306621 ]\n",
      "  [0.32344216 0.7119921 ]]\n",
      "\n",
      " [[0.32323566 0.71161145]\n",
      "  [0.37153625 0.7989113 ]\n",
      "  [1.3100034  0.6909199 ]]], shape=(3, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(kf_loss(t2, t2), (3,3,2)))\n",
    "print(tf.reshape(kf_loss(t1, t2), (3,3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# So just a little confused here why we have a vector of two values for the distance between a pair of embeddings?\n",
    "# Each value in these pairs almost exactly sum to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kf_loss_mod(string_embedding, code_embedding):\n",
    "\n",
    "  string_embedding_norm = tf.nn.l2_normalize(string_embedding, axis=1)\n",
    "  code_embedding_norm = tf.nn.l2_normalize(code_embedding, axis=1)\n",
    "  tf.logging.debug(\"string_embedding_norm: %s\" % string_embedding_norm)\n",
    "  tf.logging.debug(\"code_embedding_norm: %s\" % code_embedding_norm)\n",
    "\n",
    "  # All-vs-All cosine distance matrix, reshaped as row-major.\n",
    "  cosine_dist = 1.0 - tf.matmul(string_embedding_norm, code_embedding_norm,\n",
    "                                transpose_b=True)\n",
    "  cosine_dist_flat = tf.reshape(cosine_dist, [-1, 1])\n",
    "  tf.logging.debug(\"cosine_dist_flat: %s\" % cosine_dist_flat)\n",
    "\n",
    "  # Positive samples on the diagonal, reshaped as row-major.\n",
    "  label_matrix = tf.eye(tf.shape(cosine_dist)[0], dtype=tf.int32)\n",
    "  label_matrix_flat = tf.reshape(label_matrix, [-1])\n",
    "  tf.logging.debug(\"label_matrix_flat: %s\" % label_matrix_flat)\n",
    "\n",
    "  #logits = tf.concat([1.0 - cosine_dist_flat, cosine_dist_flat], axis=1)\n",
    "  logits = tf.maximum(0.0, cosine_dist_flat)\n",
    "  tf.logging.debug(\"logits: %s\" % logits)\n",
    "\n",
    "  labels = tf.one_hot(label_matrix_flat, 1)\n",
    "  tf.logging.debug(\"labels: %s\" % labels)\n",
    "\n",
    "  loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels,\n",
    "                                                 logits=logits)\n",
    "  tf.logging.debug(\"loss: %s\" % loss)\n",
    "\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.6931472  0.6523636  0.6670625 ]\n",
      " [0.6523636  0.69314724 0.57598215]\n",
      " [0.6670625  0.57598215 0.6931472 ]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.75979847 0.65807045 0.5866487 ]\n",
      " [0.67854947 0.75979847 0.67465085]\n",
      " [0.6750176  0.59750694 0.69537944]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Makes more sense, but still shouldn't values on diag be zero? Perhaps I missed something.\n",
    "\n",
    "print(tf.reshape(kf_loss_mod(t2, t2), (3,3)))\n",
    "print(tf.reshape(kf_loss_mod(t1, t2), (3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=99935, shape=(3, 3), dtype=float32, numpy=\n",
      "array([[0.        , 0.11669868, 0.14713186],\n",
      "       [0.11669844, 0.        , 0.        ],\n",
      "       [0.14713186, 0.        , 0.        ]], dtype=float32)>, <tf.Tensor: id=99936, shape=(3, 3), dtype=float32, numpy=\n",
      "array([[0.        , 0.11669844, 0.14713186],\n",
      "       [0.11669868, 0.        , 0.        ],\n",
      "       [0.14713186, 0.        , 0.        ]], dtype=float32)>)\n",
      "(<tf.Tensor: id=99980, shape=(3, 3), dtype=float32, numpy=\n",
      "array([[0.        , 0.2997247 , 0.1678657 ],\n",
      "       [0.25770772, 0.        , 0.00305521],\n",
      "       [0.10343069, 0.29179513, 0.        ]], dtype=float32)>, <tf.Tensor: id=99981, shape=(3, 3), dtype=float32, numpy=\n",
      "array([[0.        , 0.2997247 , 0.29254252],\n",
      "       [0.25770772, 0.        , 0.12773204],\n",
      "       [0.        , 0.16711831, 0.        ]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The slicenet similarity cost produces a single loss value instead of pairwise distances\n",
    "\n",
    "print(slicenet_similarity_cost(t2, t2))\n",
    "print(slicenet_similarity_cost(t1, t2))\n",
    "\n",
    "# If this is summed we'll get the total distance from all elements to their non-pairs, ignoring self-distances.\n",
    "# Perhaps we should also consider self-distances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_initializer(_):\n",
    "  return None\n",
    "\n",
    "class SimilarityTransformer(t2t_model.T2TModel):\n",
    "  \"\"\"Transformer Model for Similarity between two strings.\n",
    "  This model defines the architecture using two transformer\n",
    "  networks, each of which embed a string and the loss is\n",
    "  calculated as a Binary Cross-Entropy loss. Normalized\n",
    "  Dot Product is used as the distance measure between two\n",
    "  string embeddings.\n",
    "  \"\"\"\n",
    "\n",
    "  def top(self, body_output, _):  # pylint: disable=no-self-use\n",
    "    return body_output\n",
    "\n",
    "  def body(self, features):\n",
    "        \n",
    "    loss_variant = self.hparams.loss_variant\n",
    "\n",
    "    initializer = _get_initializer(self.hparams.initializer)\n",
    "    docs_encoder_trainable = self.hparams.docs_encoder_trainable\n",
    "    code_encoder_trainable = self.hparams.code_encoder_trainable\n",
    "\n",
    "    with tf.variable_scope('string_embedding'):\n",
    "      string_embedding = self.encode(features, 'inputs')\n",
    "      tf.logging.debug(\"string_embedding: %s\" % string_embedding)\n",
    "\n",
    "    if 'targets' in features:\n",
    "      with tf.variable_scope('code_embedding'):\n",
    "        code_embedding = self.encode(features, 'targets')\n",
    "        tf.logging.debug(\"code_embedding: %s\" % code_embedding)\n",
    "    \n",
    "      loss = self.loss(string_embedding, code_embedding, loss_variant)\n",
    "    \n",
    "      return string_embedding, {\"training\": loss}\n",
    "    \n",
    "    return string_embedding, {\"training\": 0.0}\n",
    "    \n",
    "  def loss(self, string_embedding, code_embedding, loss_variant):\n",
    "    \"\"\"Compute either the kfnet or slicenet cosine similarity loss.\"\"\"\n",
    "\n",
    "    if loss_variant == \"slicenet\":\n",
    "      loss = slicenet_similarity_cost(string_embedding, code_embedding)\n",
    "    elif loss_variant == \"kfnet\":\n",
    "      loss = kf_loss(string_embedding, code_embedding)\n",
    "    else:\n",
    "      raise ValueError(\"Unrecognize loss variant: %s\" % loss_variant)\n",
    "    return loss\n",
    "\n",
    "  def encode(self, features, input_key):\n",
    "    hparams = self._hparams\n",
    "    inputs = common_layers.flatten4d3d(features[input_key])\n",
    "\n",
    "    (encoder_input, encoder_self_attention_bias, _) = (\n",
    "        transformer.transformer_prepare_encoder(inputs, problem.SpaceID.EN_TOK,\n",
    "                                                hparams))\n",
    "\n",
    "    encoder_input = tf.nn.dropout(encoder_input,\n",
    "                                  1.0 - hparams.layer_prepostprocess_dropout)\n",
    "    encoder_output = transformer.transformer_encoder(\n",
    "        encoder_input,\n",
    "        encoder_self_attention_bias,\n",
    "        hparams,\n",
    "        nonpadding=transformer.features_to_nonpadding(features, input_key))\n",
    "\n",
    "    encoder_output = tf.reduce_mean(encoder_output, axis=1)\n",
    "\n",
    "    return encoder_output\n",
    "\n",
    "  def infer(self, features=None, **kwargs):\n",
    "    del kwargs\n",
    "\n",
    "    predictions, _ = self(features)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensor2tensor.models.transformer import transformer_base\n",
    "\n",
    "def similarity_transformer_tiny():\n",
    "  hparams = transformer_base()\n",
    "  hparams.num_hidden_layers = 2\n",
    "  hparams.hidden_size = 128\n",
    "  hparams.filter_size = 512\n",
    "  hparams.num_heads = 4\n",
    "  hparams.docs_encoder_trainable = True\n",
    "  hparams.code_encoder_trainable = True\n",
    "  hparams.initializer = None\n",
    "  hparams.loss_variant = \"kfnet\"\n",
    "  return hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:53,513] Setting T2TModel mode to 'train'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from /mnt/nfs-east1-d/cs/data/github_function_docstring-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:53,517] Reading data files from /mnt/nfs-east1-d/cs/data/github_function_docstring-train*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:53,622] partition: 0 num_data_files: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hparams = similarity_transformer_tiny()\n",
    "hparams.data_dir = data_dir\n",
    "\n",
    "p_hparams = problem_object.get_hparams(hparams)\n",
    "\n",
    "model = SimilarityTransformer(\n",
    "    hparams, tf.estimator.ModeKeys.TRAIN, p_hparams\n",
    ")\n",
    "\n",
    "batch_size = 1\n",
    "train_dataset = problem_object.dataset(Modes.TRAIN, data_dir)\n",
    "train_dataset = train_dataset.repeat(None).batch(batch_size)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and examine result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8185_128.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:53,838] Transforming feature 'inputs' with symbol_modality_8185_128.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming 'targets' with symbol_modality_8185_128.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:54,046] Transforming 'targets' with symbol_modality_8185_128.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:54,056] Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping T2TModel top and loss because training loss returned from body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-09-30 17:11:54,304] Skipping T2TModel top and loss because training loss returned from body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 0.521\n",
      "Step: 1, Loss: 0.382\n",
      "Step: 2, Loss: 0.307\n",
      "Step: 3, Loss: 0.289\n",
      "Step: 4, Loss: 0.262\n",
      "Step: 5, Loss: 0.252\n",
      "Step: 6, Loss: 0.251\n",
      "Step: 7, Loss: 0.249\n",
      "Step: 8, Loss: 0.246\n",
      "Step: 9, Loss: 0.239\n",
      "Step: 10, Loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@tfe.implicit_value_and_gradients\n",
    "def loss_fn(features):\n",
    "  _, losses = model(features)\n",
    "  return losses[\"training\"]\n",
    "\n",
    "NUM_STEPS = 10\n",
    "\n",
    "for count, example in enumerate(tfe.Iterator(train_dataset)):\n",
    "  loss, gv = loss_fn(example)\n",
    "  optimizer.apply_gradients(gv)\n",
    "\n",
    "  if count % 1 == 0:\n",
    "   print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))\n",
    "  if count >= NUM_STEPS:\n",
    "   break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starts monitoring network notifications and recording http responses .\n",
      "def StartMonitoringNetwork self self ClearResponseData self _inspector_websocket RegisterDomain Network self _OnNetworkNotification request method Network enable self _inspector_websocket SyncRequest request\n",
      "tf.Tensor(\n",
      "[[ 0.7172416   0.92741555  0.12348276 -0.20051704 -1.1058692   0.86038166\n",
      "  -1.2172744  -1.3298419   0.745497   -0.7550367  -0.5932518  -1.4806631\n",
      "   0.51983285  2.0449784  -1.5088761  -0.03365893 -0.04511219 -1.5894246\n",
      "   0.5326434  -0.15864295  1.1758411  -0.36474767  1.169934    1.35163\n",
      "  -0.68106705  0.37723333  1.5279374  -0.6439409   1.1116624  -1.3295312\n",
      "  -0.2936      1.3362228   1.5472255   0.69980896 -0.38871604 -0.75966763\n",
      "  -1.0516654   0.21517804 -0.68333787 -1.1471457  -0.4602326  -0.90439755\n",
      "   1.0481467  -0.4632301   0.44710428 -0.31434947  0.11345819 -0.8577829\n",
      "   2.047798    1.849212    0.83297217  1.0712117   0.01263916  0.16294779\n",
      "  -1.6924348   0.34745318 -0.5920931  -0.00282303  1.4379827   1.2685648\n",
      "   0.5572372  -0.47432387 -0.8787298  -1.2523605   0.43582553 -0.03982605\n",
      "  -1.171925   -0.03156656  0.16268024  0.20871828 -1.8749715   1.231881\n",
      "   0.04343405 -1.1466601   0.49357864 -0.81759864 -1.0872605   0.43209314\n",
      "   0.2467176   0.5664384   0.55628335 -1.79271    -0.3517144  -1.2960815\n",
      "  -0.25661913 -0.00950066  1.2609054   0.50136787 -0.49579668  1.3572885\n",
      "  -0.6965053   1.5499637   0.7631103   0.48662132  0.49756348 -1.1084802\n",
      "   0.50245005  0.68427116  1.4349906   0.5294686  -1.2174406  -0.69948924\n",
      "  -0.32913443 -0.4541477  -0.7223845  -0.585871    0.295759   -0.02945508\n",
      "   0.01469632  0.83158785 -0.80873615  0.08937953  0.06199192 -1.1561704\n",
      "   1.8292726  -0.5187636  -1.0476617   0.54972017 -1.1025183  -0.64750326\n",
      "  -0.2848444   1.2976964  -0.07066263 -0.58832884  1.5069823  -0.44018343\n",
      "  -0.8798096   0.2885494 ]], shape=(1, 128), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 7.08830416e-01  9.59957778e-01  2.59350210e-01 -3.25375736e-01\n",
      "  -1.01346457e+00  7.66593754e-01 -1.30521452e+00 -9.29190397e-01\n",
      "   9.74998236e-01 -5.69825172e-01 -6.26125991e-01 -1.63055968e+00\n",
      "   5.70797145e-01  1.61083043e+00 -1.89593554e+00 -3.37788314e-01\n",
      "   2.60486871e-01 -1.69937849e+00  6.59676671e-01 -2.32827678e-01\n",
      "   1.17587030e+00 -1.97461769e-01  1.31875122e+00  1.23877203e+00\n",
      "  -1.05760306e-01  4.66397643e-01  1.15484869e+00 -5.73187590e-01\n",
      "   1.22266436e+00 -1.26666129e+00 -3.48913223e-01  1.43716550e+00\n",
      "   1.59122348e+00  8.61291528e-01  1.19754032e-03 -6.34198010e-01\n",
      "  -1.37515748e+00  2.25602493e-01 -7.22838461e-01 -9.41629648e-01\n",
      "  -1.36725962e-01 -1.29893780e+00  9.41083372e-01 -4.71266240e-01\n",
      "   4.41422284e-01 -6.01690650e-01  2.73266792e-01 -6.79800510e-01\n",
      "   1.92636979e+00  2.11189985e+00  9.89028633e-01  1.00055552e+00\n",
      "   2.47176379e-01  1.88229710e-01 -1.63329065e+00  5.08577488e-02\n",
      "  -2.25900352e-01  1.38117924e-01  1.31356382e+00  9.05627370e-01\n",
      "   1.00407910e+00 -4.12294298e-01 -4.65574384e-01 -1.02000296e+00\n",
      "   7.30154455e-01  1.62465170e-01 -1.04644203e+00 -3.62701148e-01\n",
      "   3.39492112e-01  1.74172863e-01 -1.66280580e+00  1.30310869e+00\n",
      "   1.22165633e-02 -8.67950976e-01  5.87014675e-01 -5.12762606e-01\n",
      "  -1.14903319e+00  2.21712053e-01  1.72065243e-01  6.89689159e-01\n",
      "  -3.97373326e-02 -1.83514404e+00 -6.73583090e-01 -1.48553681e+00\n",
      "  -4.25534457e-01 -1.72524899e-01  1.14882970e+00  2.70933002e-01\n",
      "  -7.27333009e-01  1.07137179e+00 -8.19279552e-01  1.51845610e+00\n",
      "   8.36504340e-01  4.17879015e-01  1.41855806e-01 -1.13290548e+00\n",
      "   5.18598557e-01  6.60776556e-01  1.30304658e+00  2.68152624e-01\n",
      "  -1.14245582e+00 -9.15288746e-01 -2.81506449e-01 -4.37986791e-01\n",
      "  -3.72984409e-01 -5.90919316e-01  6.58471406e-01  3.54663432e-01\n",
      "  -5.18278740e-02  8.66345942e-01 -5.14252722e-01  3.17841619e-01\n",
      "   1.36166543e-01 -1.60118413e+00  1.63090634e+00 -2.56195515e-01\n",
      "  -1.45839298e+00  3.79483432e-01 -9.65634525e-01 -3.85187447e-01\n",
      "  -2.81540394e-01  1.29387271e+00 -6.36131465e-02 -9.95290399e-01\n",
      "   1.34380567e+00 -5.34311235e-01 -1.25211859e+00  7.66215334e-03]], shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example = tfe.Iterator(train_dataset).next()\n",
    "\n",
    "print(decode(example[\"inputs\"]))\n",
    "print(decode(example[\"targets\"]))\n",
    "\n",
    "print(model.infer({\"inputs\": example[\"inputs\"]}))\n",
    "print(model.infer({\"inputs\": example[\"targets\"]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine distances between pairs and non-pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def random_airquote_code_airquote():\n",
    "  codelen = random.randint(10,100)\n",
    "  code = []\n",
    "  for i in range(0, codelen):\n",
    "    N = random.randint(1,10)\n",
    "    code.append(''.join(random.choice(string.ascii_lowercase) for _ in range(N)))\n",
    "  return ' '.join(code)\n",
    "\n",
    "def compare_to_random(query, code):\n",
    "    \n",
    "    code2 = random_airquote_code_airquote()\n",
    "\n",
    "    with tfe.restore_variables_on_create(ckpt_path):\n",
    "\n",
    "      doc_emb = model.infer(encode(query))\n",
    "      code1_emb = model.infer(encode(code1))\n",
    "      code2_emb = model.infer(encode(code2))\n",
    "\n",
    "    dtrue = model.loss(doc_emb, code1_emb, \"kfnet\")\n",
    "    dfalse = model.loss(doc_emb, code2_emb, \"kfnet\")\n",
    "    print(\"Dist for true pair: %s\" % dtrue)\n",
    "    print(\"Dist for false pair: %s\" % dfalse)\n",
    "    \n",
    "    return dtrue, dfalse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist for true pair: tf.Tensor([[1.2818332 0.6717591]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2767197 0.6682996]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"print query\"\n",
    "code1 = \"def my_function(query):  print(query)\"\n",
    "code2 = \"nronfg vmo5i n6565-23 wrdnds vdmam65 3ehn bdp\"\n",
    "\n",
    "doc_emb = model.infer(encode(query))\n",
    "code1_emb = model.infer(encode(code1))\n",
    "code2_emb = model.infer(encode(code2))\n",
    "\n",
    "print(\"Dist for true pair: %s\" % model.loss(doc_emb, code1_emb, \"kfnet\"))\n",
    "print(\"Dist for false pair: %s\" % model.loss(doc_emb, code2_emb, \"kfnet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist for true pair: tf.Tensor([[1.2711855 0.6645619]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2465297  0.64799166]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=83353, shape=(1, 2), dtype=float32, numpy=array([[1.2711855, 0.6645619]], dtype=float32)>,\n",
       " <tf.Tensor: id=83400, shape=(1, 2), dtype=float32, numpy=array([[1.2465297 , 0.64799166]], dtype=float32)>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_to_random(query, code1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_pair_non_pair_distances():\n",
    "\n",
    "    num_steps = 10\n",
    "    doc_emb_last = None\n",
    "    code_emb_last = None\n",
    "\n",
    "    for step in range(0, num_steps):\n",
    "\n",
    "        example = tfe.Iterator(train_dataset).next()\n",
    "\n",
    "        #print(decode(example[\"inputs\"]))\n",
    "        #print(decode(example[\"targets\"]))\n",
    "\n",
    "        doc_emb = model.infer({\"inputs\": example[\"inputs\"]})\n",
    "        code_emb = model.infer({\"inputs\": example[\"targets\"]})\n",
    "\n",
    "        print(\"Dist for true pair: %s\" % model.loss(doc_emb, code_emb, \"kfnet\"))\n",
    "\n",
    "        if doc_emb_last is not None:\n",
    "          print(\"Dist for false pair: %s\" % model.loss(doc_emb, code_emb_last, \"kfnet\"))\n",
    "          # Assuming examples are well shuffled...\n",
    "\n",
    "        print('\\n')\n",
    "        doc_emb_last = doc_emb\n",
    "        code_emb_last = code_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist for true pair: tf.Tensor([[1.2899535  0.67726463]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2899222 0.6772435]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2910588 0.6780152]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2851241  0.67398864]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2964038  0.68164814]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2921448  0.67875284]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2831182 0.6726295]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.3063977  0.68845767]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.3056698  0.68796104]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2883658 0.6761871]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.289762  0.6771347]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.281821  0.6717509]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2766623 0.6682608]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.301272  0.6849625]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2982606 0.6829117]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2951511  0.68079615]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2922087  0.67879623]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2735832 0.6661805]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2883599  0.67618304]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_pair_non_pair_distances()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate a long training run\n",
    "\n",
    "Assuming relevant model and problem versions are in t2t_usr_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train locally, e.g. using tiny hparams to check that things run okay.\n",
    "\n",
    "!t2t-trainer --t2t_usr_dir=/mnt/nfs-east1-d/work/tk/tk \\\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tk.experiment import configure_experiment, T2TExperiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_args:\n",
      "{'data_dir': '/mnt/nfs-east1-d/data',\n",
      " 'dbgprofile': False,\n",
      " 'hparams': \"''\",\n",
      " 'hparams_set': 'similarity_transformer_tiny',\n",
      " 'log_device_placement': False,\n",
      " 'model': 'similarity_transformer_dev',\n",
      " 'output_dir': '/mnt/nfs-east1-d/work/tk/output',\n",
      " 'problem': 'github_function_docstring',\n",
      " 'profile': False,\n",
      " 'ps_gpu': 1,\n",
      " 'save_checkpoints_secs': 1800,\n",
      " 'schedule': 'train',\n",
      " 'ssd_mount_path': '/mnt/disks/ssd0',\n",
      " 'train_steps': 100000,\n",
      " 'worker_gpu': 1,\n",
      " 'worker_gpu_memory_fraction': 0.95}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Your favorite way to launch jobs here, e.g. Faring, ksonnet, a Python\n",
    "# wrapper around ksonnet, etc.\n",
    "\n",
    "# In my case I'm currently using this (unsupported) library\n",
    "\n",
    "args = configure_experiment(\"cs-dev-100k\",\n",
    "                             problem=\"github_function_docstring\",\n",
    "                             num_gpu_per_worker=1,\n",
    "                             hparams_set=\"similarity_transformer_tiny\",\n",
    "                             model=\"similarity_transformer_dev\",\n",
    "                             extra_hparams={\n",
    "                             },\n",
    "                             num_steps=100000)\n",
    "                             #base_image=\"gcr.io/kubeflow-rl/common-base:0.0.3\")\n",
    "\n",
    "job = T2TExperiment(**args)\n",
    "job.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the above trains but doesn't make any progress. Need a way to test loss functions\n",
    "# locally with batch sizes greater than 1. Training could be improved either with an\n",
    "# improved loss function or an improved training strategy (e.g. pre-training).\n",
    "\n",
    "# On the cloud this is training with batch size 4096.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_args:\n",
      "{'data_dir': '/mnt/nfs-east1-d/data',\n",
      " 'dbgprofile': False,\n",
      " 'hparams': \"''\",\n",
      " 'hparams_set': 'similarity_transformer_tiny',\n",
      " 'log_device_placement': False,\n",
      " 'model': 'similarity_transformer_dev',\n",
      " 'output_dir': '/mnt/nfs-east1-d/work/tk/output',\n",
      " 'problem': 'github_function_docstring',\n",
      " 'profile': False,\n",
      " 'ps_gpu': 1,\n",
      " 'save_checkpoints_secs': 1800,\n",
      " 'schedule': 'train',\n",
      " 'ssd_mount_path': '/mnt/disks/ssd0',\n",
      " 'train_steps': 1000,\n",
      " 'worker_gpu': 4,\n",
      " 'worker_gpu_memory_fraction': 0.95}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Works with multiple GPUs?\n",
    "\n",
    "args = configure_experiment(\"cs-dev-gpu4\",\n",
    "                             problem=\"github_function_docstring\",\n",
    "                             hparams_set=\"similarity_transformer_tiny\",\n",
    "                             model=\"similarity_transformer_dev\",\n",
    "                             extra_hparams={\n",
    "                             },\n",
    "                             num_gpu_per_worker=4,\n",
    "                             num_steps=1000)\n",
    "\n",
    "job = T2TExperiment(**args)\n",
    "job.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Identifying event files in experiment subdirectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-13 14:42:05,575] Identifying event files in experiment subdirectories...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing experiment events (1 of 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-13 14:42:06,609] Processing experiment events (1 of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processing experiment events (2 of 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-13 14:42:06,926] Processing experiment events (2 of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished loading event data for comparison.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-13 14:42:07,243] Finished loading event data for comparison.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tk.allen_demo import event_data_for_comparison, show_experiment_loss\n",
    "%matplotlib inline\n",
    "\n",
    "experiment_data = event_data_for_comparison(\"gs://kubeflow-rl-checkpoints/comparisons/cs-dev-gpu4*\")\n",
    "show_experiment_loss(experiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_args:\n",
      "{'data_dir': '/mnt/nfs-east1-d/data',\n",
      " 'dbgprofile': False,\n",
      " 'hparams': \"''\",\n",
      " 'hparams_set': 'similarity_transformer_tiny',\n",
      " 'log_device_placement': False,\n",
      " 'model': 'similarity_transformer_dev',\n",
      " 'output_dir': '/mnt/nfs-east1-d/work/tk/output',\n",
      " 'problem': 'github_function_docstring',\n",
      " 'profile': False,\n",
      " 'ps_gpu': 1,\n",
      " 'save_checkpoints_secs': 1800,\n",
      " 'schedule': 'train',\n",
      " 'ssd_mount_path': '/mnt/disks/ssd0',\n",
      " 'train_steps': 1000,\n",
      " 'worker_gpu': 1,\n",
      " 'worker_gpu_memory_fraction': 0.95}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Works distributed?\n",
    "\n",
    "args = configure_experiment(\"cs-dev-ps4\",\n",
    "                             problem=\"github_function_docstring\",\n",
    "                             num_gpu_per_worker=1,\n",
    "                             hparams_set=\"similarity_transformer_tiny\",\n",
    "                             model=\"similarity_transformer_dev\",\n",
    "                             extra_hparams={\n",
    "                             },\n",
    "                             num_ps=4,\n",
    "                             num_steps=1000)\n",
    "\n",
    "job = T2TExperiment(**args)\n",
    "job.run()\n",
    "\n",
    "# This looks mis-configured - currently master doesn't wait for / connect to workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_args:\n",
      "{'data_dir': '/mnt/nfs-east1-d/data',\n",
      " 'dbgprofile': False,\n",
      " 'hparams': \"''\",\n",
      " 'hparams_set': 'similarity_transformer_tiny',\n",
      " 'log_device_placement': False,\n",
      " 'model': 'similarity_transformer_dev',\n",
      " 'output_dir': '/mnt/nfs-east1-d/work/tk/output',\n",
      " 'problem': 'github_function_docstring',\n",
      " 'profile': False,\n",
      " 'ps_gpu': 1,\n",
      " 'save_checkpoints_secs': 1800,\n",
      " 'schedule': 'train',\n",
      " 'ssd_mount_path': '/mnt/disks/ssd0',\n",
      " 'train_steps': 1000,\n",
      " 'worker_gpu': 1,\n",
      " 'worker_gpu_memory_fraction': 0.95}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = configure_experiment(\"cs-dev-base\",\n",
    "                            problem=\"github_function_docstring\",\n",
    "                            hparams_set=\"similarity_transformer_tiny\",\n",
    "                            model=\"similarity_transformer_dev\",\n",
    "                            extra_hparams={\n",
    "                            },\n",
    "                            num_gpu_per_worker=1,\n",
    "                            num_steps=1000,\n",
    "                            base_image=\"gcr.io/kubeflow-rl/common-base:0.0.3\")\n",
    "\n",
    "job = T2TExperiment(**args)\n",
    "job.run()\n",
    "\n",
    "# Works with new common base?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do kind of need to be able to test run losses with batch size greater than 1 if it's a\n",
    "# batch-wide instead of element-wise loss... \n",
    "\n",
    "# Ability to unit test losses locally with batch size > 1.\n",
    "# Pre-training, markov clustering loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The path to checkpoints for the newly trained model, accessible to local FS\n",
    "\n",
    "ckpt_path = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the distance for pair and non-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist for true pair: tf.Tensor([[1.2757524 0.6676459]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2516866  0.65144634]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "query = \"print query\"\n",
    "code = \"def my_function(query):  print(query)\"\n",
    "\n",
    "with tfe.restore_variables_on_create(ckpt_path):\n",
    "    compare_to_random(query, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist for true pair: tf.Tensor([[1.2839055  0.67316276]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2889736  0.67659956]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2806787 0.6709776]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.291646 0.678414]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2848523  0.67380446]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2833872 0.6728116]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2894423 0.6769176]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.28843   0.6762306]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2856084  0.67431694]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2573394 0.65524  ]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.265234  0.6605499]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2984159  0.68301743]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2773019 0.6686932]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2814064 0.6714702]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2907321 0.6777933]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.2787306 0.6696594]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2937149  0.67981976]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Dist for true pair: tf.Tensor([[1.3027829  0.68599224]], shape=(1, 2), dtype=float32)\n",
      "Dist for false pair: tf.Tensor([[1.2830472 0.6725814]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tfe.restore_variables_on_create(ckpt_path):\n",
    "    show_pair_non_pair_distances()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-build the search index with the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: For the sake of model development, it would be nice if this could be done with a single command,\n",
    "# provided the path to new checkpoints, and be triggered from the notebook.\n",
    "\n",
    "def rebuild_index(ckpt_path):\n",
    "  \"\"\"Trigger a re-build of the search index.\n",
    "  \n",
    "  i.e. triggers external infrastructure to re-compute embeddings\n",
    "  \n",
    "  Returns:\n",
    "      index or index ID?\n",
    "  \"\"\"\n",
    "    \n",
    "  index_id = None\n",
    "\n",
    "  return index_id\n",
    "\n",
    "index_id = rebuild_index(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run queries against the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: hello world\n",
      "Hits:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search(query, ckpt_path, index_id):\n",
    "\n",
    "  with tfe.restore_variables_on_create(ckpt_path):\n",
    "    doc_emb = model.infer(encode(query))\n",
    "\n",
    "  # TODO: Search `doc_emb` against index with `index_id`\n",
    "  hits = []\n",
    "\n",
    "  return hits\n",
    "\n",
    "\n",
    "query = \"hello world\"\n",
    "\n",
    "hits = search(query, ckpt_path, None)\n",
    "\n",
    "print(\"Query: %s\" % query)\n",
    "print(\"Hits:\")\n",
    "pprint.pprint(hits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute interpretable quality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Trigger calculation of an interpretable measure of quality, along\n",
    "# the lines of\n",
    "# https://github.com/kubeflow/examples/issues/254#issuecomment-425606539\n",
    "\n",
    "def compute_quality(ckpt_path, index_id):\n",
    "  pass\n",
    "\n",
    "compute_quality(ckpt_path, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export and serving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
